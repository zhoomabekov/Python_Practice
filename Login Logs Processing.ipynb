{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfa840ff-a296-41b6-8b0b-00fd9419a979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              date         time      PC name            user name\n",
      "6   Fri 09/01/2023  10:31:20.62  011108499NU          abdul.wahab\n",
      "10  Fri 09/01/2023  10:30:41.34  000553011NU     nazym.alipbayeva\n",
      "12  Fri 09/01/2023  10:28:11.77  000580520NU  eldar.sharafutdinov\n",
      "25  Fri 09/01/2023  10:20:22.48  000580519NU       aibek.shokayev\n",
      "26  Fri 09/01/2023  10:19:15.87  NLT069054NU     kassym.talgatuly\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read both files into DataFrames\n",
    "loginlogs_df = pd.read_csv(\"loginlogs.txt\", sep=\" ; \", header=None, names=[\"date\", \"time\", \"PC name\", \"user name\"], engine='python')\n",
    "school_pcs_df = pd.read_csv(\"School_PCs.txt\", sep=\" ; \", header=None, names=[\"Inventory number\", \"Asset name\", \"Asset type\", \"Location\", \"Responsible\", \"Position\", \"Year\", \"Comment\"], engine='python')\n",
    "\n",
    "# Step 2: Extract inventory numbers from School_PCs.txt\n",
    "inventory_numbers = school_pcs_df[\"Inventory number\"]\n",
    "\n",
    "# Step 3: Filter loginlogs_df to include only rows with PC names containing inventory numbers\n",
    "df = loginlogs_df[loginlogs_df[\"PC name\"].str.contains('|'.join(map(str, inventory_numbers)), case=False)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29b38a6-f396-4d97-a7ae-33c24ed0b525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have untouched df\n",
    "Original_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b407738-604e-469f-a049-66cc92338784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For resetting df\n",
    "df = Original_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4915730-8517-4483-be9a-f0de0f562c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column to store the original date values\n",
    "df.loc[:,'Original_Date'] = df['date'].copy()\n",
    "\n",
    "# Converting all data in \"date\" column into Timestamp\n",
    "date_format_1 = '%a %m/%d/%Y'\n",
    "date_format_2 = '%d.%m.%Y'\n",
    "date_format_3 = '%d/%m/%Y'\n",
    "date_format_4 = '%d-%b-%y'\n",
    "date_format_5 = '%Y-%m-%d'\n",
    "date_format_6 = '%m/%d/%Y'\n",
    "\n",
    "# Applying different date formats\n",
    "df.loc[:, 'date'] = pd.to_datetime(df['date'], errors='coerce', format=date_format_1).combine_first(\n",
    "    pd.to_datetime(df['date'], errors='coerce', format=date_format_2)).combine_first(\n",
    "    pd.to_datetime(df['date'], errors='coerce', format=date_format_3)).combine_first(\n",
    "    pd.to_datetime(df['date'], errors='coerce', format=date_format_4)).combine_first(\n",
    "    pd.to_datetime(df['date'], errors='coerce', format=date_format_5)).combine_first(\n",
    "    pd.to_datetime(df['date'], errors='coerce', format=date_format_6))\n",
    "\n",
    "# Filling errors with previous non-error value\n",
    "df['date'] = df['date'].fillna(method='ffill')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f400c2f9-40a6-4d37-af85-4f42a1028ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e58168-862d-4948-b8d2-839d490e048a",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_only = df[df['date'].isna()]\n",
    "errors_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae233818-ef3a-4d97-a8ca-f60c1adb87c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_counts = errors_only['Original_Date'].value_counts(dropna=False)\n",
    "dict(date_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a8ef6f-790c-419f-b555-0063209d8e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the previous and next values after the NaN are the same\n",
    "\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Find the indices of rows containing NaT values in the 'date' column\n",
    "nan_indices = df.index[df['date'].isna()]\n",
    "\n",
    "# Create a list to store the rows to be extracted\n",
    "rows_to_extract = []\n",
    "\n",
    "# Iterate through the NaN indices\n",
    "for idx in nan_indices:\n",
    "    # Get the index of the row before the NaN\n",
    "    prev_idx = idx - 1 if idx > 0 else None\n",
    "    # Get the index of the row after the NaN\n",
    "    next_idx = idx + 1 if idx < len(df) - 1 else None\n",
    "\n",
    "    # Append the rows to the list (including the NaN row and its neighbors)\n",
    "    if prev_idx is not None:\n",
    "        rows_to_extract.append(df.iloc[prev_idx])\n",
    "    rows_to_extract.append(df.iloc[idx])\n",
    "    if next_idx is not None:\n",
    "        rows_to_extract.append(df.iloc[next_idx])\n",
    "\n",
    "# Create a new DataFrame from the extracted rows\n",
    "result_df = pd.DataFrame(rows_to_extract)\n",
    "result_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419aaaa-c3c3-4daf-bc05-064326c05e37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615793a4-de6f-4935-ba2a-a66e775c6c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the time differences between consecutive rows\n",
    "df['time_diff'] = df['date'].diff()\n",
    "\n",
    "# Find the maximum time difference\n",
    "max_time_diff = df['time_diff'].max()\n",
    "\n",
    "# Find the rows corresponding to the maximum time difference\n",
    "max_time_diff_rows = df[df['time_diff'] == max_time_diff]\n",
    "\n",
    "# Print the result\n",
    "print(\"Maximum Time Difference:\", max_time_diff)\n",
    "print(\"Rows with Maximum Time Difference:\")\n",
    "print(max_time_diff_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daf7360-0646-4389-b2c0-a7ca2efb4b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(df['time_diff'][2000:3000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c02c23c3-337f-4af5-b4ee-4a48ff90af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = len(df['date'])\n",
    "na_count = df['date'].isna().sum()\n",
    "print(f'Percentage of NaT is: {round(na_count/count*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7d3116-7627-4e93-b6c5-5ee1911827f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a71107-047e-4132-9c5f-8503f111a0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.NaT\n",
    "df.loc[df[\"date\"] == date, \"Original_Date\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3582b8-6e3d-410f-85c6-6d52daaa3f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46aacac-e8ef-40fd-9624-937990dab854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c816938-6e66-48e8-9f0a-cb21db4f1491",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_num = \"NLT061083NU\"\n",
    "df.loc[df[\"PC name\"] == inv_num, \"date\"].iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f160e953-366c-4a33-b6b9-e6b68d0e30b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_loginlogs_df[filtered_loginlogs_df[\"user name\"] == \"abay.kasken\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8092273-d116-49ba-b50a-59740d526d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_num = \"NLT060945\"\n",
    "school_pcs_df[school_pcs_df[\"Inventory number\"] == inv_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42ec7db-b75f-485b-8861-fa542c1fe7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = pd.Timestamp('2065-02-23 00:00:00')\n",
    "\n",
    "df[df[\"date\"] == date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c6291-6c86-4e58-965c-402a1cbcc26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_counts = df['date'].value_counts(dropna=False)\n",
    "dict(date_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350cc643-af99-4410-8f47-7d485ab55b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0e845c-64a8-4b03-b814-0421b2a7ab8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c95ffd2-8748-4d12-9713-8be13655b22b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd5e70-41dd-4ff4-a0e3-e96468e2d5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432326b8-e55a-4a4d-aabf-ed90666658be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f48940f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<p>Bacon ipsum dolor amet shoulder doner tenderloin ham hock short loin chicken swine.  Jowl shankle ball tip, sirloin shank spare ribs ham.  Cow frankfurter bacon doner chislic drumstick pork loin ground round bresaola porchetta swine.  Chicken bacon jowl tail andouille.</p>\\n<p>Bacon boudin turducken, rump cupim corned beef pork meatloaf.  Picanha kevin boudin biltong buffalo, tenderloin leberkas.  Sausage swine bacon biltong drumstick landjaeger burgdoggen filet mignon strip steak doner jowl meatball.  Beef ribs short loin short ribs, meatloaf pork belly chicken tenderloin landjaeger jowl turkey pig filet mignon kielbasa alcatra salami.</p>\\n<p>Venison pork loin boudin meatloaf pig tail burgdoggen chuck porchetta short loin pork belly.  Tongue shankle beef ribs, short loin capicola prosciutto sausage pork belly hamburger ham ham hock chuck spare ribs beef turducken.  Filet mignon hamburger tri-tip tongue burgdoggen.  Flank ribeye andouille fatback beef ribs, pastrami salami jowl pancetta t-bone sirloin drumstick shoulder corned beef.  Frankfurter swine drumstick sirloin boudin kevin pork loin landjaeger beef ribs ground round andouille ribeye chicken leberkas turducken.  Landjaeger pancetta picanha t-bone, sirloin beef short ribs venison flank andouille.  Sirloin rump andouille kevin fatback corned beef ground round beef tri-tip turducken.</p>\\n'\n",
      "\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get('https://baconipsum.com/api/?type=all-meat&paras=3&start-with-lorem=1&format=html')\n",
    "\n",
    "print(r.content)\n",
    "print()\n",
    "print(r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a3fcad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<!doctype html><html><head><meta charset=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width,initial-scale=1\"/><link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/favicon/apple-touch-icon.png\"><link rel=\"icon\" href=\"/favicon/favicon.svg\" sizes=\"32x32\" type=\"image/svg+xml\"><link rel=\"icon\" href=\"/favicon/favicon-32x32.png\" sizes=\"32x32\" type=\"image/png\"><link rel=\"icon\" href=\"/favicon/favicon.ico\" sizes=\"32x32\" type=\" image/x-icon\"><link rel=\"manifest\" href=\"/favicon/manifest.json\"><link rel=\"mask-icon\" href=\"/favicon/safari-pinned-tab.svg\" color=\"#000000\"><link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.5.2/animate.min.css\"/><meta name=\"msapplication-TileColor\" content=\"#2b5797\"><meta name=\"theme-color\" content=\"#ffffff\"><script type=\"text/javascript\" src=\"/ruxitagentjs_ICA27NVfgjqrux_10255221104040649.js\" data-dtconfig=\"rid=RID_877240681|rpid=1421691979|domain=jusan.kz|reportUrl=/rb_48c88acb-e2e8-45ae-9fc4-1656eaf32570|app=06c17601f7c05d56|rcdec=1209600000|featureHash=ICA27NVfgjqrux|vcv=2|rdnt=1|uxrgce=1|bp=3|srmcrv=10|cuc=uchimf76|mel=100000|dpvc=1|ssv=4|lastModification=1671529441075|dtVersion=10255221104040649|srmcrl=1|tp=500,50,0,1|uxdcw=1500|agentUri=/ruxitagentjs_ICA27NVfgjqrux_10255221104040649.js\"></script><script>!function(e,t,a,n,g){e[n]=e[n]||[],e[n].push({\"gtm.start\":(new Date).getTime(),event:\"gtm.js\"});var m=t.getElementsByTagName(a)[0],r=t.createElement(a);r.async=!0,r.src=\"https://www.googletagmanager.com/gtm.js?id=GTM-WVP33JP\",m.parentNode.insertBefore(r,m)}(window,document,\"script\",\"dataLayer\")</script><link rel=\"stylesheet\" href=\"https://bot-contact.p-s.kz/widget/prod/jysanbank/css/app.css\"><script defer=\"defer\" src=\"/static/js/main.75161c24.js\"></script><link href=\"/static/css/main.630891e9.css\" rel=\"stylesheet\"></head><body><noscript><iframe src=\"https://www.googletagmanager.com/ns.html?id=GTM-WVP33JP\" height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe></noscript><noscript>\\xd0\\x92\\xd0\\xb0\\xd0\\xbc \\xd0\\xbd\\xd0\\xb5\\xd0\\xbe\\xd0\\xb1\\xd1\\x85\\xd0\\xbe\\xd0\\xb4\\xd0\\xb8\\xd0\\xbc\\xd0\\xbe \\xd0\\xb2\\xd0\\xba\\xd0\\xbb\\xd1\\x8e\\xd1\\x87\\xd0\\xb8\\xd1\\x82\\xd1\\x8c JavaScript, \\xd1\\x87\\xd1\\x82\\xd0\\xbe\\xd0\\xb1\\xd1\\x8b \\xd0\\xb7\\xd0\\xb0\\xd0\\xbf\\xd1\\x83\\xd1\\x81\\xd1\\x82\\xd0\\xb8\\xd1\\x82\\xd1\\x8c \\xd1\\x8d\\xd1\\x82\\xd0\\xbe \\xd0\\xbf\\xd1\\x80\\xd0\\xb8\\xd0\\xbb\\xd0\\xbe\\xd0\\xb6\\xd0\\xb5\\xd0\\xbd\\xd0\\xb8\\xd0\\xb5.</noscript><div id=\"root\"></div></body></html>'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\galym.zhumabekov\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'jusan.kz'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "r = requests.get('https://baconipsum.com/api/?type=meat-and-filler')\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fab3bd1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\galym.zhumabekov\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:1013: InsecureRequestWarning: Unverified HTTPS request is being made to host 'jusan.kz'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\GALYM~1.ZHU\\AppData\\Local\\Temp/ipykernel_1220/1458622927.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'https://jusan.kz/exchange-rates'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtexts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# делаем из полученных байтов Python-объект для удобной работы\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# проверяем тип сконвертированных данных\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json  # импортируем необходимую библиотеку\n",
    " \n",
    " \n",
    "r = requests.get('https://jusan.kz/exchange-rates', verify=False)\n",
    "texts = json.loads(r.content)  # делаем из полученных байтов Python-объект для удобной работы\n",
    "print(type(texts))  # проверяем тип сконвертированных данных\n",
    " \n",
    "for text in texts:  # выводим полученный текст. Но для того чтобы он влез в консоль, оставим только первые 50 символов.\n",
    "    print(text[:50], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a58a3dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_user_url: https://api.github.com/user\n",
      "current_user_authorizations_html_url: https://github.com/settings/connections/applications{/client_id}\n",
      "authorizations_url: https://api.github.com/authorizations\n",
      "code_search_url: https://api.github.com/search/code?q={query}{&page,per_page,sort,order}\n",
      "commit_search_url: https://api.github.com/search/commits?q={query}{&page,per_page,sort,order}\n",
      "emails_url: https://api.github.com/user/emails\n",
      "emojis_url: https://api.github.com/emojis\n",
      "events_url: https://api.github.com/events\n",
      "feeds_url: https://api.github.com/feeds\n",
      "followers_url: https://api.github.com/user/followers\n",
      "following_url: https://api.github.com/user/following{/target}\n",
      "gists_url: https://api.github.com/gists{/gist_id}\n",
      "hub_url: https://api.github.com/hub\n",
      "issue_search_url: https://api.github.com/search/issues?q={query}{&page,per_page,sort,order}\n",
      "issues_url: https://api.github.com/issues\n",
      "keys_url: https://api.github.com/user/keys\n",
      "label_search_url: https://api.github.com/search/labels?q={query}&repository_id={repository_id}{&page,per_page}\n",
      "notifications_url: https://api.github.com/notifications\n",
      "organization_url: https://api.github.com/orgs/{org}\n",
      "organization_repositories_url: https://api.github.com/orgs/{org}/repos{?type,page,per_page,sort}\n",
      "organization_teams_url: https://api.github.com/orgs/{org}/teams\n",
      "public_gists_url: https://api.github.com/gists/public\n",
      "rate_limit_url: https://api.github.com/rate_limit\n",
      "repository_url: https://api.github.com/repos/{owner}/{repo}\n",
      "repository_search_url: https://api.github.com/search/repositories?q={query}{&page,per_page,sort,order}\n",
      "current_user_repositories_url: https://api.github.com/user/repos{?type,page,per_page,sort}\n",
      "starred_url: https://api.github.com/user/starred{/owner}{/repo}\n",
      "starred_gists_url: https://api.github.com/gists/starred\n",
      "topic_search_url: https://api.github.com/search/topics?q={query}{&page,per_page}\n",
      "user_url: https://api.github.com/users/{user}\n",
      "user_organizations_url: https://api.github.com/user/orgs\n",
      "user_repositories_url: https://api.github.com/users/{user}/repos{?type,page,per_page,sort}\n",
      "user_search_url: https://api.github.com/search/users?q={query}{&page,per_page,sort,order}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    " \n",
    " \n",
    "r = requests.get('https://api.github.com')\n",
    " \n",
    "dicts = json.loads(r.content)  # делаем из полученных байтов Python-объект для удобной работы\n",
    "# print(type(dicts))\n",
    "\n",
    "for k, v in dicts.items():\n",
    "    print(f'{k}: {v}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf4717e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'{\\n  \"args\": {}, \\n  \"data\": \"\", \\n  \"files\": {}, \\n  \"form\": {\\n    \"key\": \"value\"\\n  }, \\n  \"headers\": {\\n    \"Accept\": \"*/*\", \\n    \"Accept-Encoding\": \"gzip, deflate, br\", \\n    \"Content-Length\": \"9\", \\n    \"Content-Type\": \"application/x-www-form-urlencoded\", \\n    \"Host\": \"httpbin.org\", \\n    \"User-Agent\": \"python-requests/2.26.0\", \\n    \"X-Amzn-Trace-Id\": \"Root=1-63a0b3ba-0d6029e64e7c36ef533f34d1\"\\n  }, \\n  \"json\": null, \\n  \"origin\": \"95.56.111.52\", \\n  \"url\": \"https://httpbin.org/post\"\\n}\\n'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    " \n",
    " \n",
    "r = requests.post('https://httpbin.org/post', data = {'key':'value'})  # отправляем POST-запрос\n",
    "print(r.content)  # содержимое ответа и его обработка происходит так же, как и с GET-запросами, разницы никакой нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea226f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incididunt prosciutto elit drumstick veniam irure.  Corned beef meatball pork, spare ribs cow doner exercitation leberkas andouille ex ea voluptate.  Nostrud occaecat shankle tenderloin capicola minim chislic.  Cupim andouille dolor tenderloin.  Pancetta irure deserunt, jowl aliqua doner shankle turkey ham hock shank dolor venison est.  Pork belly pariatur tri-tip meatball lorem pastrami doner pork kielbasa short loin spare ribs sint ad aliqua bacon.\n"
     ]
    }
   ],
   "source": [
    "'''Напишите программу, которая отправляет запрос на генерацию случайных текстов \n",
    "(используйте этот сервис): https://baconipsum.com/api/ \n",
    "Выведите первый из сгенерированных текстов.'''\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "r = requests.get('https://baconipsum.com/api/?type=meat-and-filler')\n",
    "texts = json.loads(r.content)\n",
    "\n",
    "print(texts[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04971ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102cb775",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bc89ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5aaa2ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Welcome to Python.org']\n"
     ]
    }
   ],
   "source": [
    "import requests  # импортируем наш знакомый модуль\n",
    "import lxml.html\n",
    "from lxml import etree\n",
    " \n",
    " \n",
    " \n",
    "html = requests.get('https://www.python.org/').content  # получим html главной странички официального сайта python\n",
    " \n",
    "tree = lxml.html.document_fromstring(html)\n",
    "title = tree.xpath('/html/head/title/text()')  # забираем текст тега <title> из тега <head>, который лежит в свою очередь внутри тега <html> (в этом невидимом теге <head> у нас хранится основная информация о страничке, её название и инструкции по отображению в браузере) \n",
    " \n",
    "print(title)  # выводим полученный заголовок страницы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f662d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "//*[@id=\"content\"]/div/section/div[3]/div[1]/div/ul/li[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1a94747",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (126293024.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 8\u001b[1;36m\u001b[0m\n\u001b[1;33m    ul = tree.findall('ul = tree.findall('/body/div/div[3]/div/section/div[2]/div[1]/div/ul/li'))  ')  # помещаем в аргумент метода findall скопированный xpath. Здесь мы получим все элементы списка новостей. (Все заголовки и их даты)\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import requests  # импортируем наш знакомый модуль\n",
    "import lxml.html\n",
    "from lxml import etree\n",
    " \n",
    "# создадим объект ElementTree. Он возвращается функцией parse() \n",
    "tree = etree.parse('Welcome to Python.org.html', lxml.html.HTMLParser())  # попытаемся спарсить наш файл с помощью html-парсера. Сам html - это то, что мы скачали и поместили в папку из браузера.\n",
    " \n",
    "ul = tree.findall('ul = tree.findall('/body/div/div[3]/div/section/div[2]/div[1]/div/ul/li')  # помещаем в аргумент метода findall скопированный xpath. Здесь мы получим все элементы списка новостей. (Все заголовки и их даты)  \n",
    " \n",
    "# создаём цикл, в котором мы будем выводить название каждого элемента из списка\n",
    "for li in ul:\n",
    "    a = li.find('a')  # в каждом элементе находим, где хранится заголовок новости. У нас это тег <a>. Т. е. гиперссылка, на которую нужно нажать, чтобы перейти на страницу с новостью. (Гиперссылки в html это всегда тег <a>)\n",
    "    print(a.text)  # из этого тега забираем текст, это и будет нашим названием"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
